# vLLM 分布式推理

## 参考文档

[大模型推理：vllm多机多卡分布式本地部署_vllm 多卡部署-CSDN博客](https://blog.csdn.net/sunny0121/article/details/139331035)

[vLLM分布式多GPU Docker部署踩坑记 | LittleFish’Blog](https://www.xiaoiluo.com/article/vllm-gpu-ray-multigpu#google_vignette)

[Distributed Inference and Serving &#8212; vLLM](https://docs.vllm.ai/en/stable/serving/distributed_serving.html#distributed-inference-and-serving)
